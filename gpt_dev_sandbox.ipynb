{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Building a GPT\n",
        "\n",
        "Companion notebook to the [Zero To Hero](https://karpathy.ai/zero-to-hero.html) video on GPT."
      ],
      "metadata": {
        "id": "wJpXpmjEYC_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/terleckimaciej/neural_nets_training.git\n",
        "#%cd neural_nets_training/\n",
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYOuGru3YW5u",
        "outputId": "77c05e97-3e94-46f7-cb41-02ab540ee4a8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5hjCcLDr2WC",
        "outputId": "fc1db3d8-c7e6-438b-8e0d-a3b0d51470fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-12 09:52:11--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2026-01-12 09:52:11 (22.0 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read it in to inspect it\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "O6medjfRsLD9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of dataset in characters: \", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xWI_VyAsN8F",
        "outputId": "3525018f-a0e1-453c-ee5f-6c4a3ef26d63"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters:  1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's look at the first 1000 characters\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c5V0FvqseE0",
        "outputId": "445bb11d-ffab-4050-d5e8-50a3fe2dc961"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e-Rbyr8sfM8",
        "outputId": "efc6dcfb-c6c3-481c-997e-507babbe3dce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "najprostszy encoder - openai uzywa np tiktoken"
      ],
      "metadata": {
        "id": "fxZttYapD6yO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"hii there\"))\n",
        "print(decode(encode(\"hii there\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw1LKNCgwjj1",
        "outputId": "7665e129-e6b9-4daa-d8a1-c5ea31e3a5e1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lLK_oPmIrsJC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
        "import torch # we use PyTorch: https://pytorch.org\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJb0OXPwzvqg",
        "outputId": "83de5c86-3ebe-45c1-8745-7ef3b70fb753"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now split up the data into train and validation sets\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "f_WIXqxz0lU5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD5Bj8Y6IAD4",
        "outputId": "2d2ca1c8-7159-4542-d6d3-9df334022c6f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HXDe8vGJCEn",
        "outputId": "98cbbf11-50ec-4365-d35d-9fadfdc992cd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([18]) the target: 47\n",
            "when input is tensor([18, 47]) the target: 56\n",
            "when input is tensor([18, 47, 56]) the target: 57\n",
            "when input is tensor([18, 47, 56, 57]) the target: 58\n",
            "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for predictions?\n",
        "\n",
        "\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,)) #pierwszy argument (max_value) - maksymalny indeks\n",
        "                                                              #od ktorego mozemy zaczac sekwencje czyli dlugosc danych - rozmiar batcha\n",
        "                                                              #drugi argument (num_samples,) - indeks ile losowych liczb od 0 do max_value\n",
        "                                                              #wygenerowac. czyli ix bedzie tensorem czterech (batch_size) losowych indeksow\n",
        "                                                              # od 0 do do max_value = len(data)-batch_size\n",
        "\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])       # laczenie sekwencji tensorow wzdluz nowego wymiaru\n",
        "                                                              # czyli cos jak ulozenie \"plaskich\" tensorow w stos/stack\n",
        "                                                              # dla kazdego wylosowanego i indeksu z ix wez sekwencje od tego indeksu do\n",
        "                                                              # konca naszego rozmiaru batcha\n",
        "\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])   # dla kazdego indeksu i tworzy sekwencje block_size znakow, ktora jest przesunieta\n",
        "                                                              # czyli nasze cele (targety) do przewidzenia\n",
        "    return x, y\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90df818a-4eb0-4913-e3a8-e6c8c609bc72",
        "id": "ulY63twSVdpm"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
            "----\n",
            "when input is [24] the target: 43\n",
            "when input is [24, 43] the target: 58\n",
            "when input is [24, 43, 58] the target: 5\n",
            "when input is [24, 43, 58, 5] the target: 57\n",
            "when input is [24, 43, 58, 5, 57] the target: 1\n",
            "when input is [24, 43, 58, 5, 57, 1] the target: 46\n",
            "when input is [24, 43, 58, 5, 57, 1, 46] the target: 43\n",
            "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
            "when input is [44] the target: 53\n",
            "when input is [44, 53] the target: 56\n",
            "when input is [44, 53, 56] the target: 1\n",
            "when input is [44, 53, 56, 1] the target: 58\n",
            "when input is [44, 53, 56, 1, 58] the target: 46\n",
            "when input is [44, 53, 56, 1, 58, 46] the target: 39\n",
            "when input is [44, 53, 56, 1, 58, 46, 39] the target: 58\n",
            "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52] the target: 58\n",
            "when input is [52, 58] the target: 1\n",
            "when input is [52, 58, 1] the target: 58\n",
            "when input is [52, 58, 1, 58] the target: 46\n",
            "when input is [52, 58, 1, 58, 46] the target: 39\n",
            "when input is [52, 58, 1, 58, 46, 39] the target: 58\n",
            "when input is [52, 58, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
            "when input is [25] the target: 17\n",
            "when input is [25, 17] the target: 27\n",
            "when input is [25, 17, 27] the target: 10\n",
            "when input is [25, 17, 27, 10] the target: 0\n",
            "when input is [25, 17, 27, 10, 0] the target: 21\n",
            "when input is [25, 17, 27, 10, 0, 21] the target: 1\n",
            "when input is [25, 17, 27, 10, 0, 21, 1] the target: 54\n",
            "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xb) # our input to the transformer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpyyAeIzQjlO",
        "outputId": "c8e50cef-6b04-4135-ad28-9c94017478c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "        #Pomyśl o tym jak o dużej tabeli: W tej tabeli mamy vocab_size wierszy (po jednym dla każdego unikalnego znaku w naszym słowniku).\n",
        "        #Każdy wiersz ma vocab_size kolumn. Wartości w tych kolumnach to \"logity\" (czyli surowe, nieskończone \"punkty\") dla przewidywania następnego znaku.\n",
        "        #Jak to działa? Kiedy model widzi znak o identyfikatorze X, po prostu \"patrzy\" na X-ty wiersz tej tabeli.\n",
        "        #Wiersz ten zawiera vocab_size liczb, gdzie każda liczba mówi, jak prawdopodobne jest, że dany znak ze słownika (0 do vocab_size-1) będzie następnym.\n",
        "        #To dlatego nn.Embedding ma vocab_size zarówno dla pierwszego, jak i drugiego argumentu –\n",
        "        #bo wejście to indeks znaku, a wyjście to logity dla wszystkich możliwych następnych znaków.\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        # idx and targets are both (B,T) tensor of integers.\n",
        "        # B-atch, T-ime. idx - tensor wejsciowy, targets - tensor celow\n",
        "        # sluzy do obliczenia loss-u\n",
        "\n",
        "        # dla kazdego znaku w idx model szuka w tabeli embeddingu tokenow odpowiadajacego mu wiersza (w ktorym p-bienstwa wystapienia nastepnego znaku)\n",
        "        # idx ma ksztalt (B, T) wiec logits ma (B, T, C), gdzie C (Chanell) to vocab_size (dlugosc slownika unikalnych tokenow)\n",
        "        # dla kazdej sekwencji znakow i dla kazdego znaku w tej sekwencji mamy vocab_size liczb mowiacych jak prawdopodobny jest kazdy mozliwy nastepny znak\n",
        "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
        "\n",
        "        #jesli nie podalismy targets czyli np. chcielismy tylko wygenerowac tekst, nie trenowac model, nie liczmy straty\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "          #rozpakowujemy ksztalt logits (embedding) na batch size, time i vocab_size\n",
        "            B, T, C = logits.shape\n",
        "            #techniczna podmianka ksztaltu, bo pozniej funkcja F.cross_enropy (loss) oczekuje jednego argumentu, wiec laczymy wymiary batch i time w jeden dlugi\n",
        "            # przez to z (4, 8, 65) robi sie (32, 65) czyli mamy 32 niezalezne przeiwdywania, gdzie kazde ma 65 mozliwych znakow\n",
        "            logits = logits.view(B*T, C)\n",
        "            # targets tez zmieniamy tak, aby pasowaly do logits - z (4, 8) robi sie (32). teraz mamy 32 odpowiedzi (id znakow) dla kazdego przewidywania\n",
        "            targets = targets.view(B*T)\n",
        "            #obliczamy loss\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    # pozwala modelowi \"pisac\" nowy tekst. potrzebuje poczatkowego idx - pierwszego znaku, od ktorego zacznie i max_new_tokens - ile ma znakow wygenerowac\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens): #generowanie jednego znaku, az nie bedzie ich max_new_tokens\n",
        "            # get the predictions - wykonanie kroku forward na idx, nie dajemy targets wiec loss bedzie None\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C). bierzemy tylko logit z ostatniego znaku biezacego kontekstu - bo tylko ten jest nam potrzebny\n",
        "                                      # do przewidzenia nastepnego znaku (ktorego jeszcze nie ma)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C) - przeksztalcenie surowe logity (dowolne liczby) w takie  z zakresu 0-1, ktore sumuja sie do 1.\n",
        "                                              # dzieki temu sa interpretowalne jako pradopodobienstwo\n",
        "            # sample from the distribution - branie \"losowo\" nastepnego znaku. losowo, ale z wagami prawdopodobienstwa obliczonymi wczesniej -\n",
        "            # im wyzsze pd-bienstwo tym czesciej dany znak bedzie sie losowal, ale bedzie roznorodnosc odpowiedzi, nie zawsze to samo\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "                              # tutaj jest zero do inicjalizacji 1x1 z zerem. ma to sens zwlaszcza w tym przypadku, bo 0 oznacza w naszym decodingu poczatek nowej\n",
        "                              # linii. przy innym encodowaniu trzeba bedzie zwrocic na to uwage, byc moze jakos zastapic, na pewno rozwazyc\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nql_1ER53oCf",
        "outputId": "09b44f9d-8793-4b41-9605-aaed67e65468"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
            "wnYWmnxKWWev-tDqXErVKLgJ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "na razie powyzej mamy model bigramowy, po pierwwsze totalnei losowe przewidywanie (stad taki zd upy string) - nie bylo jeszcze treningu dla uzyskania embeddigow sensownych, po drugie bigram patrzy tylko na jeden znak przed tym, ktory ma przewidziec, wiec na razie nie spelnia on funkcji przewidywania na podstawie calego kontekstu tego, co bylo wczesniej - jest to zatem praktycznie tylko demonstracja najprostszego mozliwego wariantu, ktory dziala\n"
      ],
      "metadata": {
        "id": "J8nDkSRIfLDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "eTyJ8qAaDdiF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for steps in range(10000): # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs4kI8YdEkQj",
        "outputId": "025b767c-a4a7-4fa0-a757-e24dfc9176f7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.382369041442871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "koniec konwergencji jakos na 2.4 - zeszlismy z 4,6"
      ],
      "metadata": {
        "id": "eZE06ZIjxBn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcVIDWAZEtjN",
        "outputId": "c2658142-d701-461a-c8a9-eba68c1f862a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lso br. ave aviasurf my, yxMPZI ivee iuedrd whar ksth y h bora s be hese, woweee; the! KI 'de, ulseecherd d o blllando;LUCEO, oraingofof win!\n",
            "RIfans picspeserer hee tha,\n",
            "TOFonk? me ain ckntoty ded. bo'llll st ta d:\n",
            "ELIS me hurf lal y, ma dus pe athouo\n",
            "BEY:! Indy; by s afreanoo adicererupa anse tecorro llaus a!\n",
            "OLeneerithesinthengove fal amas trr\n",
            "TI ar I t, mes, n IUSt my w, fredeeyove\n",
            "THek' merer, dd\n",
            "We ntem lud engitheso; cer ize helorowaginte the?\n",
            "Thak orblyoruldvicee chot, p,\n",
            "Bealivolde Th li\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The mathematical trick in self-attention"
      ],
      "metadata": {
        "id": "XinV8nmAnmKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tril(torch.ones(3, 3))\n",
        "a1 = torch.sum(a, 1, keepdim=True)\n",
        "a2 = a / torch.sum(a, 1, keepdim=True)\n",
        "print(a)\n",
        "print(a1)\n",
        "print(a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXLEVRquA4XH",
        "outputId": "e37daa40-0169-4da0-aee5-5587c14d0fae"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vX43_DCXA4WL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "teraz sprobujemy uwzglednic wszystkie poprzedzajace przewidywany token tokeny dla danego batch'a - na razie w formie brania po prostu obsranej sredniej z prawdopodobienstw wszystkich wczesniejszych tokenow"
      ],
      "metadata": {
        "id": "IbA4w6i_TGM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
        "#czyli w jaki sposob możemy uzyskać ważoną agregację, a zatem średnią kumulatywnej\n",
        "# tak działają mechanizmy uwagi w transformerach - możemy w ten sposób uśredniać embeddingi\n",
        "# z poprzednich tokenów\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3, 3)) #macierz z jedynkami przekształcona by elementy\n",
        "                                  # powyżej przekątnej się wyzerowały\n",
        "a = a / torch.sum(a, 1, keepdim=True) #sumowanie elementy każdego wiersza macierzy a\n",
        "                                      # keepdim - wymiar pozostaje (3 kol)\n",
        "                                      # dzielimy a przez nią i znormalizowalismy by\n",
        "                                      # wiersze dodawały się do 1. rozłożyłem to\n",
        "                                      # w następnej komórce. mamy teraz \"macierz wag\"\n",
        "                                      # niezbędną do policzenia średniej kumulatywnej\n",
        "                                      #każdy kolejny wiersz ma wage rozłożoną na kolejną komórkę - odpowiada za kolejny token\n",
        "b = torch.randint(0,10,(3,2)).float() #losowe liczby całkowite - symulacja danych wejściowych - 3 el w sekwencji i 2 chanelle (cechy)\n",
        "c = a @ b # operator mnożenia macierzy torcha. mnożymy dane wejściowe przez  - efektem jest obliczenie wagi kumulatywnej\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tukiH-NbRBhA",
        "outputId": "719a80d8-6add-4ffa-895c-f25166162277"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# consider the following toy example:\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2 # batch, time, channels\n",
        "x = torch.randn(B,T,C) #wypełnienie tensora losowymi liczbami z rozkł. norm (0,1)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs_E24uRE8kr",
        "outputId": "38524462-1f20-4728-c5c3-c76f6cb99cf5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
        "xbow = torch.zeros((B,T,C)) # xbow - Bag of Words - average'owanie rzeczy, mamy worek slow.\n",
        "                            # inicjujemy zerami. Posłuży do przechowania wyników  obliczeń\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b,:t+1] # (t,C) - dla bieżącego batcha bierzemy wszytkie elementy do początku\n",
        "                          # do t (trzeb zrobić t+1 w pythonie)\n",
        "        xbow[b,t] = torch.mean(xprev, 0) #średnia wzdłuż kanału 0 (czyli dla każdego kanału C)\n",
        "                                         # wynik średniej (wektor o rozmiarze C) jest przypisywany\n",
        "                                         # do odpowiedniej pozycjji xbow[b, t]\n",
        "                                         # b i t do indeksy, ktore wskazuja konkretnie miejsce\n",
        "                                          #  w tensorze xbow, do którego chcemy przypisać wartosc\n",
        "                                          #  xbow bowiem to tensor o wymiarach (B, T, C), nie żadna\n",
        "                                          #  np funkcja z argumentami\n"
      ],
      "metadata": {
        "id": "86NuXX0fn7ps"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x[0], xbow[0]\n",
        "#pierwszy wiersze drugiej tabeli jest taki sam jak pierwszej - jest to jego srednia\n",
        "# drugi wiersz drugiej tabeli jest inny - jest średnią dwóch pierwszych wierszy pierwszej tabli\n",
        "# itd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KoYVUTx89jM",
        "outputId": "e51ea1a6-cd0e-40c1-b61a-49f5192f0426"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.1808, -0.0700],\n",
              "         [-0.3596, -0.9152],\n",
              "         [ 0.6258,  0.0255],\n",
              "         [ 0.9545,  0.0643],\n",
              "         [ 0.3612,  1.1679],\n",
              "         [-1.3499, -0.5102],\n",
              "         [ 0.2360, -0.2398],\n",
              "         [-0.9211,  1.5433]]),\n",
              " tensor([[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 2: using matrix multiply for a weighted aggregation\n",
        "# weights\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True) #nasz wektor wag\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C) #mnożenie wejścia przez wagi\n",
        "torch.allclose(xbow, xbow2) #sprawdzenie czy tensory są take same (z tolerancją na różnice międzyprzecinkowe wynikające z dzielenia)."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhdOAd6-wXkZ",
        "outputId": "e9d1eafe-4c46-47a9-c49f-fc018dda106c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "wyszło false, choć powinno True - teoretycznie jest tolerancja na liczby po przecinku... no ale organoleptycznie wygląda tak samo :/"
      ],
      "metadata": {
        "id": "Nu6MQ1mnQIbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print('xbow:', xbow)\n",
        "# print('xbow2:', xbow2)"
      ],
      "metadata": {
        "id": "LWeP7RZSPFKg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# version 3: use Softmax\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T,T)) #same zera - inicjalizacja\n",
        "wei = wei.masked_fill(tril == 0, float('-inf')) # wszędzie gdzie są zera wstaw -∞ (-nieskończoność)\n",
        "# to nam mówi, że: tokeny z przeszłości nie mogą komunikowac się z tokenami z przyszłości\n",
        "#dzięki zaminieniu zer na -∞, softmax nie traktuje tych wartości jako normalnej liczby (jak 0), więc nie nadaje jej wagi\n",
        "# softmax myśli: dodatnia liczba - ważne, ujemna - mało ważne, 0 - średnio ważne. A ma myśleć 0 - nie wolno. Inaczej przyszłość\n",
        "# dostanie zarówno wagę jak i gradient. Matematycznie softmax robi: exp(0)=1 (waga 1), a exp(=∞)=0 (waga 0). -∞ to sposób powiedzenia softmaxowi\n",
        "# , ze ta waga nie istnieje i ma ją olać\n",
        "\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow, xbow3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOURrfG-ysoL",
        "outputId": "7643a990-bdb0-4a81-f0cd-01da060a1cd9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('wei:\\n', wei)\n",
        "print('\\nxbow3:\\n', xbow3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6NFFVKMZprb",
        "outputId": "3fc5e845-1c0c-4e0f-9223-08395c09eedf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wei:\n",
            " tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
            "\n",
            "xbow3:\n",
            " tensor([[[ 0.1808, -0.0700],\n",
            "         [-0.0894, -0.4926],\n",
            "         [ 0.1490, -0.3199],\n",
            "         [ 0.3504, -0.2238],\n",
            "         [ 0.3525,  0.0545],\n",
            "         [ 0.0688, -0.0396],\n",
            "         [ 0.0927, -0.0682],\n",
            "         [-0.0341,  0.1332]],\n",
            "\n",
            "        [[ 1.3488, -0.1396],\n",
            "         [ 0.8173,  0.4127],\n",
            "         [-0.1342,  0.4395],\n",
            "         [ 0.2711,  0.4774],\n",
            "         [ 0.2421,  0.0694],\n",
            "         [ 0.0084,  0.0020],\n",
            "         [ 0.0712, -0.1128],\n",
            "         [ 0.2527,  0.2149]],\n",
            "\n",
            "        [[-0.6631, -0.2513],\n",
            "         [ 0.1735, -0.0649],\n",
            "         [ 0.1685,  0.3348],\n",
            "         [-0.1621,  0.1765],\n",
            "         [-0.2312, -0.0436],\n",
            "         [-0.1015, -0.2855],\n",
            "         [-0.2593, -0.1630],\n",
            "         [-0.3015, -0.2293]],\n",
            "\n",
            "        [[ 1.6455, -0.8030],\n",
            "         [ 1.4985, -0.5395],\n",
            "         [ 0.4954,  0.3420],\n",
            "         [ 1.0623, -0.1802],\n",
            "         [ 1.1401, -0.4462],\n",
            "         [ 1.0870, -0.4071],\n",
            "         [ 1.0430, -0.1299],\n",
            "         [ 1.1138, -0.1641]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uzyskaliśmy zatem równomiernie rozłożone wagi poprzednich tokenów (względem przewidywanego). Ich równomierne rozłożenie wynikało z tego, że zainicjowaliśmy je przez zera - teraz chcemy, aby inichalne wagi były dynamicznie obliczone na podstawie danych wejsciowych."
      ],
      "metadata": {
        "id": "RtynZy2gW_Om"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mechanizm self attention - problematyka\n",
        "Problem, którego rozwiązaniem jest mechanizm self-attention polega na dynamicznym, kontekstowym wyborze informacji w sekwencji. Zatem w naszym przypadku polega na wyborze \"ważności\" każdego z sekwencji tokenów poprzedzającej ten przez nas przewidywany. Ma ona zależeć od aktualnego tokena i kontekstu, a nie od pozycji, czy jakiejś stałej reguły.\n",
        "\n",
        "\n",
        "\n",
        "# niewystarczalność poprzednich podejść:\n",
        "np. bigramy, n-gramy - kontekst o odgórnej ustalonej długości, brak hierarchi znaczeń, brak uogolnienia\n",
        "\n",
        "\n",
        "inne modele Dl, np. sekwencyjne (RNN - recurrent neural networks i jego rozwinięcia jak LSTM i GRU) - mają bottlenecka - jeden wektor stanu, który potrzebuje wyniku dla t-1 - informacja z dalszego kontekstu musi \"przetrwać\" wiele kroków, w których słabnie gradient, a więc jej znaczenie. Uniemożliwia oczywiście tez jednoczesne przetwarzanie wag. Metaforycznie \"spróbuj streścić cały akapit do jednego zdania, a następnie odpowiadać na pytania dotyczące akapitu tylko na podstawie znajomości tegoż streszczenia\". W self-attention nie mamy takiej rekurencji, możemy przetwarzać równolegle. Wszystko w jednym forward passie się dzieje, równolegle.\n",
        "\n",
        "\n",
        "W CNN (Convolutional Neural Nets) problemem jest lokalne okno kontekstu, stała jego geometria, brak globalnego, selektywnego dostępu, który jest potrzebny do przetwarzania języka naturalnego (podmiot i orzeczenie mogą być daleko, nawet nie w jednym zdaniu.\n",
        "\n",
        "\n",
        "Self attention eliminuje konieczność spłaszczania kontekstu do stanu i zastępuje ją bezpośrenim, ważonym dostępem do całej historii.\n",
        "-brak wąskiego gadła stanu\n",
        "-równoległość przetwarzania (GPU może rozwinąć skrzydła)\n",
        "-koszt zależności od odległego tokena nie rośnie wraz z jego odległością (modele sekwencyjne)\n",
        "Zamiast pamięci (uwaga jak u człowieka) tworzy się coś w rodzaju bazy danych  dynamicznym zapytaniem, gdzie każde zapytanie (następny przwidywany token) ma inne kryterium podobieństwa (implikowany jego wartością). Każdy token selektywnie agreguje sobie informacje z całej historii embeddingów poprzednich tokenów"
      ],
      "metadata": {
        "id": "YvaCgB1vaRM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "każdy token wyemituje 2 wektory:\n",
        "-query\n",
        "-key,\n",
        "gdzie query to mniej więcej \"what am i looking for?\", a key \"what do I contain?\". Z tych dwóch wektorów brany jest iloczyn skalarny, który dla każdego tokena poprzedzającego token procesowany (przewidywany w następnej kolejności) mówi nam, jak bardzo nasz token \"interesuje się\" tym konkretnym poprzednim tokenem - czyli nadaje wagę bliskości/więzi tych dwóch tokenów."
      ],
      "metadata": {
        "id": "E_qxpiSthIUx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "W ten sposób uzyskujemy początkowe wagi, które wcześniej inicjowaliśmy jako zera - surowe wyniki dopasowania, które następnie znormalizujemy naszym Softmaxem. Wszystko dzieje się jeszcze przed rozpoczęsciem komunikacji między tokenami - dzięki temu, możemy ją następnie zainicjować przetwarzając równolegle.  "
      ],
      "metadata": {
        "id": "hxbO7tMikC4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# version 4: self-attention!\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32 # batch, time, channels\n",
        "x = torch.randn(B,T,C) #tworzenie\n",
        "\n",
        "# let's see a single Head perform self-attention\n",
        "head_size = 16 # hiperparametr - jedna głowa = jedna instancja mechanizmu self attention, jak poniżej. patrzy ona na 16-wymiarową projekcję tokenów\n",
        "               # normanie będziemy mieli wiele głów - każda liczy swoje wagi, widzi inne zależności (np. jedna patrzy na zgodność gramatyczną,\n",
        "               # inna na relację sematyczną, a inna na struktury dialogu), tutaj dla prostoty zostańmy przy jednej\n",
        "\n",
        "key = nn.Linear(C, head_size, bias=False) # tworzymy warstwę liniową (bardzo prosta NN bez aktywacji), która będzie przekształać wejście x (o wymiarze C)\n",
        "                                          # w wektory kluczy (k) o wymiarze . Opisują one każdy token - co on zawiera - coś jak indeks\n",
        "query = nn.Linear(C, head_size, bias=False) #podobnie, tu przekształcamy x w wektory zapytań do poszukiwania informacji\n",
        "value = nn.Linear(C, head_size, bias=False) # tu przekształcamy to w wektor wartości - rzeczywistą informację, do wyodrębnienia i zagregowania\n",
        "                                            # gdy klucz odpasuje się do zapytania\n",
        "\n",
        "k = key(x)   # (B, T, 16) | wpuszaczamy wejścioweembeddingi w tensory: kluczy,\n",
        "q = query(x) # (B, T, 16) | i zapytań\n",
        "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T) | obliczamy surowe wyniki uwagi (wcześniej inicjowane jako zera) poprzez mnożenie\n",
        "                               # macierzowe. Transpozycja zamienia miejscami T z head_size (tu 16), bo jest potrzebne do przemnożenia macierzy\n",
        "                               # Iloczyn skalarny daje nam \"wynik dopasowania\" (affinity) między tokenem aktualnym i każdym go poprzedzającym\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "#wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1) # normalizacja jw. , ma patrzeć tylko na siebie i to co było wcześniej , a wynikowe wagi mają być >=0 i sumowac się do 1 (softmax)\n",
        "\n",
        "v = value(x) # przekształcenie x w tensory wartości\n",
        "out = wei @ v # teraz wyjście wartości mnożone jest przez macierz wag inicjalnych. Dla każdego tokena out to ważona suma wektorów wartości wszystkich\n",
        "              # porzednich tokenów\n",
        "#out = wei @ x\n",
        "\n",
        "out.shape"
      ],
      "metadata": {
        "id": "mcJC_2WzmumT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d61075-525c-450f-ffd9-061bc3205c8e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes:\n",
        "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
        "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
        "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
        "- In an \"encoder\" attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
        "- \"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\",\n",
        "the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
        "- \"Scaled\" attention additional divides `wei` by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
      ],
      "metadata": {
        "id": "D9xuHBTImzk8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Poniżej przedstawione jest zastosowanie ostatniej uwagi z powyższego. W paperze \"Attention is all you need\" zdefiniowano uwagę następująco:\n",
        "\n",
        "![Zrzut ekranu 2026-01-10 182601.png](data:image/png;base64,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)\n",
        "\n",
        "Ten pierwiastek pozwala uniknąć \"rozlania się\" wag po zaaplikowaniu softmaxa. Wagi będą przez to nieproporcjonalnie \"dryfujące\", jak niżej:\n",
        "\n",
        "![Zrzut ekranu 2026-01-10 182902.png](data:image/png;base64,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)\n",
        "\n",
        "Po podzieleniu przez √(head_size) wariancja sum embeddingów jest równa 1, a nie wielkości głowy, dzięki czemu np.\n",
        "\n",
        "![Zrzut ekranu 2026-01-10 183453.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZAAAAGoCAYAAABolrMMAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAEpLSURBVHhe7Z0LlFXVecc3UQYNoLFCBwgaBvFVaygi5WEkZVmFgo/6GFrFtJQEpVXqE5e6EqS0ipWgpsiSQkqtiq7wVBSLjZYWlUeRUGoSRRGpGgTF2gRQB1Ta3+Z+N3sO59577rl3Zu6d+f/WOuveu885++zH2d9/f98+M6ddXV3dASeEEEIUiQQkATU1Ne6YY45xRx55pGvXrl0mtek4cOCA++STT9xHH33k9u3bl0kVQojK4kuZT5EDxKNHjx7uy1/+crOIB3Adrsd1ub4QQlQiEpAC4Hk0l3BE4bpcXwghKhEJSAEIW7UkLX19IYTIhQSkAC3lfRgtff1q4tFHH3WvvPKKu/jiizMpuRk8eLBbvXq1e/bZZzMpQohiKUpAGKBbt25ttGkApmfevHm+/caOHZtJEWlBNE499VTfpkuXLs2kCiGakqI9kB07drgxY8a43r17u5tuuskv9CIspXL33Xcnnj2K1gf3EB4BnkEaJkyY4H784x+7++67L5OSnzVr1rghQ4a44cOHZ1IORfekEPkpKYTFTG/Tpk2ua9eumRRRDOPGjfMG7KGHHsqkiDQgOrNnz3a33nprJkUI0RyUvAYSJx7M2Ji5WZhr8+bN7oYbbsjsPRTCOKNHj3YdO3Z0M2bMaDTr4zzOjwuZWRx70aJF/pP9zBqB4+ycMN3OCfdFj8lHv3793I9+9CN38803Z1IOcu6557olS5Zkw1Hsf/755/0WDVPxnTT2PfXUU/7cYuF826z8zOKj9Yt6h9G+yTfDpu3ZH/YdbRTtT65BOaBQ/jarnzt3rt+/YcMGv+ENdOvWzc2fP7+RJ8LxlhdbuM+YMmWKv2/smLAfo+Wxsls75fKeqU/0nnz88ccPqQ+E3pP1SVjuaHuxL1oPK6eVnTzjriVEJVGSgHCzE8Ji9mcwUEjHMyHMxYanMnHixOzgiMIsfMGCBW7v3r0+LHb66af7c8iLWTr5kw+hs86dO2eNlcHxCxcu9McwC+W8t99+O3t98mYgkm6hC9tHnoTlGNBJZrAbN2705aytrc2kHAoC8c1vftM98sgj7pxzzvGhlUsvvTQrFHgc1Jn9+/fv92lpOPHEE315rI7UCwO8atWqbNqAAQMaGa+RI0f6dQKr//bt292kSZMOMcqwdu1at3v3bte/f/9MykEBbd++fTaN88jngw8+8L+T5I9RPv744/1+8mGj/S08Sj3oJ4wo/TZz5sxsfpRnzpw5WcPKMdwTFlalzkbcvUjbJCHunrS8Bw4c6D/B6o9QUGagX2gnu+b69et9iC3sByFaA0ULiM0SGTDM0Bic4aLliBEj3LZt29yVV16ZSXHeML/xxht+UBUDeZG/xbUZoBgARCucmXG9MPbN9/Hjx2d+Obdu3Tr/F91xRp/ZK8yaNct/JuHDDz/0n6E38tWvftWn/eIXv3CnnXaae+2117KhKTyNjz/+2PXt29f/Lhe0qYnek08+6Q1wNI2yhgJAu4RthQBhgOnXKLQ3/WxeJm3epUsXL86WxnkdOnTwXgQkyR/RXLFiReZXPFyL9uLeCvOzyYoZccqBqJjxpu5W/7h7MVq+YrCQbXgfDxo0yNd/8eLFmZSD64R2XwH3VrQfCkGZbSIlRKVS0iI6GwPY3HE2jAVGI4oZknAmmg/Li9mohQJMtKLY7DeE2Z6FvghBMOuNwuy0V69e3nsxA5SEnTt3umOPPdYbOGaoX/nKV3w6IrFr1y6/74wzzsiGsL7//e97w9scxLVFFGbt+doz5N13380KNm2FsaZO1Ic0DHlDQ4P3VoxC+SPmGPZ8cC2OQ/xDMKh4NT179vS/ESKOjYaJ8t2LpYBQWt0BUaDPQ0MfChrwnbS4cK8Q1UzJayAMYAYqM7GmgLCBiZVthWZmhLgIGVjoixAEhj4EAzBq1CifT7EzUgwG/2IEkcBIHnXUUd6gYfDMYP3kJz/x4atwQ0haEupMXJ02iQv5xGEGHKHAWCIozz33nBcN0piN0wYYyTT5lwp9d/LJJ/t+JEwaFZJyg1Ba3REp+r2QNyVEa6VkAQmxmVZcqIq06MwsH/nyygdGjBlzIWFAYJjJWrgjDYgIBpbPU045xYcp4Oc//7n7+te/XnF/32Fhn+nTpyfuB9qRdurTp483lszAORfRIC0MX6XJPxd4KLSr5WlY/yJkIfQjomWhorT3TyHIlzAq+dqkKfS+4rAyh94Qk64wrIcXpf97JqqNkgWEODMD1QaRhRQIYxgWKso3UyMsBBxnMOBYkAwX35ld8gRPLgixUR4LcQBiEYawKBsDOlz8LwbWOY4++mg/4Fkg37Jli+vevXu2DngapH/rW9/KhrHCp60wsKSxn3wwfmmfxiqGaBtj2PDCCkE/4G1RX+tnDDhphOssHJU2fyC/0KgiXKw3kEfoUdCX9C/rO0D4kWPiiLsXuXeSeihx9yQwaaCsw4YN8+WOiiX3bHhNygzmzdknD1YAnkx9fb1/OMHgfD2FJSqdkhbR2cCemgFm/Rhmnv6xYzAiGMl8HgH7mOkShrCBwzmEQIijW148lfXMM89kzjoUyoFRCa/Poq+FsDAe7LPHM+0YtlxPiUVBHC644AJfFkAwoiEqS7ON4zkPeCop3Bfd31TQxhhl2pj6Tp06teDsGTB4tB/nWD9bGn2GsYe0+QOCgDDQJ7amxkIyTzBZfmwQ3m+ED60f7b60RfO4e5EHHJKWKe6eBOpLWevq6hotnhs8yMB6h12TycrkyZOz7cTn8uXLs+t7PGyBVxMNswpR6eh9IAXASLQ0b731VuabqBTsUfLoX7LnSheiNVLWNRAh2gJ4ItE1DSHaIhKQAvB2wJakpa8vDoW1i3AdRoi2igSkALxatiVp6euLX8P6GY8J8/c/5XjSTIhqR2sgBeDJI8IVLfFeDrwPFnH1XnQhRCUiD6QAGG+MOH9l3lzhJK7D9SQeQohKRh6IEEKIVMgDEUIIkQoJiBBCiFRIQIQQQqRCAiKEECIVEhAhhBCpkIAIIYRIhQRECCFEKiQgQgghUiEBEUIIkYqy/yX6Z5995j7//HP/7zhsE0II0fooiweCSHz66af+/zfxv5sQkC+++ELiIYQQrZiSBWT//v3+X44jGEIIIdoOJQlIQ0ODFxAhhBBtj9QCQsiKUJUQQoi2SSoBwfNQyEoIIdo2RQsIXoc8DyGEEEULiN6QJ4QQAooSEEJXejRXCCEEFCUgWvcQQghhJBYQ++tyIYQQAhILCP+iRAghhDASC4jCV0IIIUKKWgMRQgghjMQCovUPIYQQIc3qgaxYscJNmzYt86s4Bg8e7FauXOmuv/76TIoQQoiWRCEsIYQQqUj8Qine9VEKeB99+vTx33fu3OluvvlmN3DgQHf11Ve79u3bu71797o77rjD9erVy40ZM8bdeeed7oknnvDn8QeMXbp0cbW1tf78LVu2uBEjRvjvQgghWoZm80Aw+Bj+hQsXurPOOsuLx0UXXeTGjRvnheWZZ55xEyZMcPfff7979dVX3SWXXJINd3EcgvPOO++4Bx54QOIhhBAVQIuFsPAmjjvuOPfII494Yamvr3edO3f2ax0PPvigO+GEE9zIkSPd7NmzM2cIIYSoJFp0DQThwPuwDc9kzZo1ftu9e3fmKCGEEJVIiwkI6yDdu3ePfarq4Ycfdu+//342rCWEEKLyaFYB2bhxow9VvfTSS27dunVeIK699lrvibAhHKx79O3b1y1ZssQtW7bMh7VIxythDYTjWVgXQgjRsjTbU1hCCCFaFy26BiKEEKJ6kYAIIYRIhQRECCFEKiQgQgghUiEBEUIIkQoJiBBCiFRIQIQQQqRCAiKEECIVEhAhhBCpkIAIIYRIhQRECCFEKiQgQgghUiEBEUIIkQoJiBBCiFRIQIQQQqRCAiKEECIVEhAhhBCpkIAIIYRIhQRECCFEKiQgQgghUiEBEUIIkQoJiBBCiFRIQIQQQqRCAiKEECIVEhAhhBCpkIAIIYRIhQRECCFEKiQgQgghUiEBEUIIkQoJiBBCiFRIQIQQQqRCAiKEECIVEhAhhBCpkIAIIYRIRYsIyC233OLeeecdt2PHDr/de++9mT1CiIULF2bHxsaNG903vvGNzB4hKosW80B2797tJk6c6Lp16+ZuvPHGTGoyTIBWrVqVSUkGA5EBaYOz2PMLEQ78LVu2uPr6+sye/ETLRd2oY7mgHJTH8qecxUA72blszSX45eivsOzl7G/awPJN01/57mH6i3Hx2GOPZVKEqEyqLoSF8bv88svd9u3bMynJue6667whZXAiXj169CjamOYCg9KvX7+sKFK+22+/PdHs8cUXX/Tnch4bZbrqqqsSC1A+uD7lwBCTN+UcNGhQYhGw9rGyYdQuvPDCspStEHfddZefaHDdYvvLxAes7EOHDvW/SwXjTxvQhuS7du3aovqrlHtYiEqiqgSEgXv00Ud7Y9vQ0JBJTQ4D3AY5g5gBXFtb63+XAsZq2LBh3mCZgXv66add586d3ZAhQ/zvYmBWu2/fvsyv0rjkkkt8ORYsWOB/33PPPe6tt95yZ555pv9dCNpn586dmV/lLVs+6GsEg3YE2pX27dOnTyJRpt6IT7lEI+T888/39w5tCda2gwcP9p/5KPUeFqKSqCoBYcCed955mV+VQ/fu3V2HDh3c+vXr/W9Eihlpp06d/Ay1WAYMGOB27dqVeLadj+OOO84bO8uLz5NOOsmLShJD/PLLL7uzzz7bz7Y5nplzucqWD9oNAVi9erX/zfUpB+WmvQuBQH766aeNQndJva580AaUgXax33h49DVtXYhKvYeFSEPVhbDKBcakrq4uO8MtBxgWZskzZ850y5Ytc6+//noiowKIjhk7QkzlLBdQX/JmBj937lwveEkMMetThI8I2SxatMiXsSlm9bkYPny4Xyvg+jNmzPDeD/2WDzPyvXv3drfddpsXI0JvtDEeQLlg/cLa5IUXXiiLNytENVFxAsIAx2DYrJHBaWGncsE1yJNZtIUhSqWmpsaNHz/erVy50husJUuWeCNGXZJAWTDunIvRxoMpx4wZ8DgIsV122WU+dNKxY0cfPnnvvfcyR+SGMrDNmTPHCwnnI5JJvJdCkAd5WV+zhXVG4PB4aA/apl27dj6dEFwSEHHzlOgPPKc0HmEcV1xxhQ/tkR/3UjTUJ0RboOIEBIPOrJ2ByYbhKGe4BPHAELLwWezTX7nAEBNuYRZqeVpYC6NYLNSXsFNS7yUfCNiePXv8gjSL9UC+lNd+5wIDj/DQVvQL5WJGjzCyxlAq0YcH2Kz9aDfKjXBZ/7M/ifCRL/UrR/tFsbzxLm1iYx5P0smCEK2FVhnCskc3ozP4UDxyeTXmARUzy8ao4CkReuJ8GD16tDd2FsOHpHlzHAvItqYCNlvnfLtGEtasWeM/qTdQb4y2xfCNXG0GYWiGheKoMHIOv8v5mCzthqHGA6HubIgZ7RwKX65rUz/qaf1sDxNYe0CavgbyxquztorLO21/CVFNVJWAYAwwIBgMBjBbMYaLp2fat2/vF2M5jy06wDFchDowCEnWCAzKZl4N+eI5YbRDY5eLsF5snMfMOwyvmUhRfmbiSTGvAUEib1ufSeJ9cU08FzuXjbKSR1g2DCfeAm1WjCHOB9c20WOdwdYaTBAKQf0w4JSVcrOGQjuE3mzaviZv1lQIY+XKOxel3sNCVBLt6urqDmS+5+Xjjz/OfCsdDPbYsWPdHXfckWjQNTcMZoxKUgFoLpjxxhnwlgbRoEx4DM25wF4OKrWvgf7G66rEsgkBbfYprDgsHFJpBsVmrZUoHkwA8A6qTTwqta+FqCZazANh0BKOAcIBSUIqQrQFEGXCrMADAxI4Uam0iIAIIYSofhTCEkIIkQoJiBBCiFRIQIQQQqRCAiKEECIVEhAhhBCpSCwg9o/shBBCCJCACCGESIUERAghRCoSC8iXvqTlEiGEEL9GAiKEECIViVXhsMMOUxhLCCFElqLcCvvnh0IIIURRAnL44YfLCxFCCOEpemGjpqYm800IIURbpmgBYS1EoSwhhBBFCwggIBIRIYRo26QSEEBAFM4SQoi2S2oBARbVjzjiCP2NiBBCtEFKtvyIByLSoUMHCYkQQrQhymbxWVxHSI488kgf2sI70R8fCiFE66VdXV3dgcx3IYQQIjGKOQkhhEiFBEQIIUQqJCBCCCFSIQERQgiRCgmIEEKIVEhAhBBCpEICIoQQIhUSECGEEKmQgAghhEiFBEQIIUQqJCBCCCFSIQERQgiRCgmIEEKIVEhAhBBCpEICIoQQIhUtJiA33HCD27x5s9u6dau7++67M6lCCCGqhaIF5NFHH/VG3zZEADEohosvvtiNGzfOLV261PXu3dvdeuutmT1CCCGqhaIE5Nlnn/UGf8yYMf6TbdWqVZm9yenVq5f/3Llzp/8EvJBXXnnFi0s1M3jwYLd69WovtEII0ZpJLCAY9i5duriFCxe6NWvWZFKdGz9+vLvvvvsyv4QQQrQVivJAampqXP/+/TO/4rEZeBjmCtc4mJlPnDjRdezY0X/idXD86NGjfdqMGTOynoh5JXPnzs3mxbFcIwylWZrBuZxn+0PPxtZeQg/B0uLWYkizfMItek0gn4ceesh169bNDRkyxB8XXicsM1v0euG6ENuiRYv8dcI8IJoPnmEIv+PKJ4QQ5SSxgLBesXz5cm8YowbLwEjPmTPH7d69Oxvimjlzpk83I3jllVf6tL179/rP008/3ee5YMECn3bTTTf5NK4HiMrxxx/v82Jf586d3fz5813Xrl0bpV1zzTX+eBg5cqSbN29etgzbt293kyZN8gYVb4m8+/bt68tFWn19vVu/fn3sWgxplg+blXP69OmNPDEg77Fjx7odO3Z4A87x1BeoP78t/GftYiKCeEyYMCG7LsRGvRCjENqeslNvy4/jJBhCiOamKA8EY4rh6tGjR+zM99JLL/XiMWXKlEzKQaOKccbYpTFwGOvZs2f77xjXTZs2xaaF+UfDahs3bmxkjJ988klfTsprwjNr1iz/mQ+MPEYfITWBSwLnnHrqqY3Cf5Rv27Ztrl+/fv73iBEj/O9QxGhHxMjg+rQ94mjXJz/ypX6DBg3yacOHD/eiHBU4IYQoJ0UJCGC48BBMSMLwEF4BwhI1XBs2bHAdOnQ4ZDadFox/aFjjCMM8hMdCzOgOGDDAb9F1nTjMU4ka+STw0ECnTp18yM7KxHbiiSf6/eSNACB0+aitrfV1X7t2bSblIPwmnf1CCNFcFC0gBkJy1VVXZWfylQJihqhZeIdPwk5REIJ9+/ZlfhXGPJXQuyqGPXv2ZMNO4Ya3IIQQ1UhqAQFm7QgIngd88MEH3ihGQ1UsvDc0NBT0GsrBwIED/WfcGkUI6w2Evgiv4VnkC68ROmLdIYmnEgdixQMIVrZcWDjLwGPDMzF47DkMVRn8Jj18LFoIIZqaxALCzB4DGoJhJTxjoZfFixd7QxbO0jmGMBF/L5LP+Jrxs78RSUs0H8o9atQo/90gvEX4jfJamcNF+BDO548eEZtwXSUXUVEFvDUW8imHhfuAp8toH86hfQhphU9mIXI8RGBwffKhPJaPhdZIt/LpKSwhRHNQlAdyyimnNIrhY+BYzLY1AQzl5MmTs4vsccfkwoyjPdobGtpiIB+Mva03TJ06tdGaAQaaBWZbCGezp8uij9WCGXH2W53Y8hnoFStWeAHjOHv6jFAV9eMxZcuDp8vM6NM+hNpYr7H9r7322iFeWzQfnkjjU6EwIURz066uru5A5ruoMBAoEwp7HFgIISqFktZARNNiaxs8xSaEEJWGBKRCIHxm4S6wtZdwbUMIISoJCUiFwOI/DxvY+gehK8RDaxtCiEpFayBCCCFSIQ9ECCFEKiQgQgghUiEBEUIIkQoJiBBCiFRIQIQQQqRCAiKEECIVEhAhhBCpkIAIIYRIhQRECCFEKiQgQgghUiEBEUIIkYqy/y+szz77zH3++efuwIED2U0IIUTroyweCCLx6aefuo8//tjt27fPC8gXX3wh8RBCiFZMyQKyf/9+98knn3jBEEII0XYoSUAaGhq8gAghhGh7pBYQQlaEqoQQQrRNUgkInodCVkII0bYpWkDwOuR5CCGEKFpAeMpKCCGEKEpACF3p0VwhhBBQlIBo3UMIIYSRWEDsr8uFEEIISCwg/IsSIYQQwkgsIApfCSGECClqDUQIIYQwEguI1j+EEEKENKsHsmLFCjdt2rTMr+IYPHiwW7lypbv++uszKUIIIVoShbCEEEKkIvELpXjXRyngffTp08d/37lzp7v55pvdwIED3dVXX+3at2/v9u7d6+644w7Xq1cvN2bMGHfnnXe6J554wp/HHzB26dLF1dbW+vO3bNniRowY4b8LIYRoGZrNA8HgY/gXLlzozjrrLC8eF110kRs3bpwXlmeeecZNmDDB3X///e7VV191l1xySTbcxXEIzjvvvOMeeOABiYcQQlQALRbCwps47rjj3COPPOKFpb6+3nXu3NmvdTz44IPuhBNOcCNHjnSzZ8/OnCGEEKKSaNE1EIQD78M2PJM1a9b4bffu3ZmjhBBCVCItJiCsg3Tv3j32qaqHH37Yvf/++9mwlhBCiMqjWQVk48aNPlT10ksvuXXr1nmBuPbaa70nwoZwsO7Rt29ft2TJErds2TIf1iIdr4Q1EI5nYV0IIUTL0mxPYQkhhGhdtOgaiBBCiOpFAiKEECIVEhAhhBCpkIAIIYRIhQRECCFEKiQgQgghUiEBEUIIkQoJiBBCiFRIQIQQQqRCAiKEECIVEhAhhBCpkIAIIYRIhQRECCFEKiQgQgghUiEBEUIIkQoJiBBCiFRIQIQQQqRCAiKEECIVEhAhhBCpkIAIIYRIhQRECCFEKiQgQgghUiEBEUIIkQoJiBBCiFRIQIQQQqRCAiKEECIVEhAhhBCpkIAIIYRIhQRECCFEKiQgQgghUiEBEUIIkQoJiBBCiFRIQIQQQqRCAiKEECIVLSIgt9xyi3vnnXfcjh07/Hbvvfdm9gghmpKFCxdmx93GjRvdN77xjcweIYqnxTyQ3bt3u4kTJ7pu3bq5G2+8MZPq/A3NjW03+apVqzJ7koEY2bmIFGIF0XzjjimVcHBu2bLF1dfXZ/YUJle5IdzHVmybFCLftfMRbdO4c8M2YeN3uaB9aee0edv5uQwpdaFO5W7vUsqdZHzkqxf7GHOPPfZYJkWI9FRcCOuuu+7y4sJNjsD06NEj8QBjwF944YXeIHL+2rVr3VVXXeUHzYsvvuj69evn021jEDU0NLi33nork0N6uCb5myhu377d3X777bGGKQrlGzZsWPbcsNyAwFqZL7vsMte5c+eyGeJ8bVaIaJtSpvBc8uzTp48vM/utjZIKVD5oV9oXI2l5Dxo0yH8mgeOmTZvmtm7dmklpDHW5/PLLfT+Wk1LLfd1113lx4Ny48VGoXkKUk4oSEAwLA+Lpp5/2vxkYDDSMUBJDfP755/sBf8899/jfCxYs8J+DBw/2n1HOPPNMn3+pxpiyIQBhXtQBQz9kyBD/Ox+cg2G1c9evX+8/6+rq/GcIRhuBLRfFtlk+mBHv27cv88u54447zpeVMgNCHe4vhUsuucS3r5WX8pM/fVoIBI7jxo4d6375y19mUn8N9+HRRx/t+4QJRjkppdxA2U2guV/ou9raWv+7UL2EKDcVJSDMqjA4q1ev9r+ZTZ199tl+wHXv3t2n5QIjznEvv/xy9jczvU6dOnlDFgUj0aVLl+xALgXK1qFDh6zhZyAzE+fa1KmckDfltmuVQrFtVogBAwa4Xbt2NRJCRNB+M2PGIFv/lgLlw3ha3nyedNJJvj7UIx8cO3To0KywRcGon3feeZlf5aWUcheiUL2EKDcVF8KC4cOH+9gzoZUZM2b4WWvcbDwXxIUXLVrkXf0XXnghO0MLYeb9s5/9LDuQywFGAC9k5syZbtmyZe71118v2hBjRCx0Yl4BUE5m+OSNkQ73lYMkbRYHgmbxfEIx5j0CZaQueJDsB2b15TRwTDLIm2vMnTvXC3mhyUYlUI5ykwfjImxzIZqTihMQBhFGh7g/g6tdu3Y+Pek6xRVXXOF27tzpZ/4YNwwhv0MsVFaOWbxRU1Pjxo8f71auXOmvvWTJEi8oCGExsAYEeAIh1IV82agPQlXqjNVI0ma5QNjoJ86lz/C8MGxAOz/++OO+TWztBrHhGuWAmTuhQ/JGmDp27Og9nPfeey9zRGVSjnLTtrQj7V/uyYQQSakoAWFGtmfPHjdnzpysZ4BhSjK4bG2AWb8ZKAxsnBGPxv1LhbJxbWbu9kSZhbVs5p0EvACEDRHJN0tH+Mox0y6mzZJAn9Gu5nXRzgg/bcK1CGFxvdGjR/v9pUD5uFfCtuK65J+v7VqacpQb8aAteeDB7jchWoKKEhBi4wwkPBAMGRszNWat4eAy9z/6CCOxfGZ3NgO2Bcs1a9b432DeRy63n/0M8mJm+JSNMhLC4XzASEbj/fnyNvG47bbbsuKZCwxzuNYAacoNSdqM/MiX/K1+cbAv6tmRl5WHBwpYvyEfI2neUax8GFJAAJnN23oOpM07KfQZ96G1XRKSlBty5U09TDxM9IVoKSpKQDDENrCIx1tMPulAYTbGo7mEZBh8rKGEBhmDEre+EILBxzhj+IqZ4VNGmxFybcI61CXJrBKjQCybxWvWODifzQSS8lsaG7BYGpK23IXaLB/U2dY/2Kgv3qO1rYXh6Ef2cy3yDWfNJr7t27f33mZSyIdyIljkbetOYd65MGHhPB7SoL0oo4lvWC/ElY3vcRMWKGadq5RyA5MH2opycz6bCWSheglRbtr9v+E6kPmel48//jjzrXS42XnU8I477khkqJobDAWGOKkAVArVWm5m2RhtjGk1xfPNG4iKYjVAm9vfHlXTvSIqi4p8CqulYFAxe6s2I1yt5baZfrWJh8304zwqIdoSLeaBYOhwxYEQigahEE0Pgkd4C3j4Qx6IKIUWERAhhBDVj0JYQgghUiEBEUIIkQoJiBBCiFRIQIQQQqRCAiKEECIViQXE/qmhEEIIARIQIYQQqZCACCGESEViAfnSl7RcIoQQ4tdIQIQQQqQisSocdthhCmMJIYTIUpRbYf/8UAghhChKQA4//HB5IUIIITxFL2zU1NRkvgkhhGjLFC0grIUolCWEEKJoAQEERCIihBBtm1QCAgiIwllCCNF2SS0gwKL6EUccob8REUKINkjJlh/xQEQ6dOggIRFCiDZE2Sw+i+sIyZFHHulDW3gn+uNDIYRovbSrq6s7kPkuhBBCJEYxJyGEEKmQgAghhEiFBEQIIUQqJCBCCCFSIQERQgiRCgmIEEKIVEhAhBBCpEICIoQQIhUSECGEEKmQgAghhEiFBEQIIUQqJCBCCCFSIQERQgiRCgmIEEKIVEhAhBBCpKLiBOTZZ5/1GwwePNitXr06+1sIIUTlkEpALr74YvfKK6+4rVu3Zjd+ky6EEKJtULSAPProo+7uu+928+bNc717985ub731luvVq1fmqPKwZs0aN2TIEDd8+PBMihBCiEqhqFfaIhyjRo1ykydPdkuXLs2klhcLV0k0hBCisknsgbAeMXToULdp06a84oHIhKEt21jLwGuJC3Xh1bCfa4TYGgj74YYbbnCbN2/21xBCCNGyJBaQQYMGuc6dO7sNGzZkUuK59dZbG4W2FixY4Pbu3eumT5/unnrqKX/MwIED/ScgEhyHyBCyEkIIUR0UtQayb98+t23btsyvwuAx4G0sX77cey1seDD9+vXLHHFQmDp06OAWL16cScnNfffd504++WQvUkIIIVqWogSkpqYm8UI5nkV9fb0XnNDg48F06dIlG8bq37+/27VrV5OtqQghhGgaEguIeR61tbX+sxDXXHON/5wyZYr/NNauXesaGhp8GAuR6dmzp1uxYkVmrxBCiGohsYDgIWzfvt0vpEcXu6MQuurbt69buHDhIesa/F61apUPYxG+AkRFCCFEdVFUCMu8iTlz5hzyJNWyZcuyax7jxo3zax2sWcSxbt06vyA/bNgw9+677yZePNdTWEIIUTkUJSD2h32Iw4wZMxo9pstCOIIxYcIE17FjR39cuD98TBdvZvfu3a6uri7R4rkQQojKo6g/JCwn+oNBIYSoboryQMoFYa4ePXq4jRs3ZlKEEEJUGy0iIJdeeqkPYT355JOZFCGEENVGswqILYLzhBZ/ma6/PBdCiOqlxdZAhBBCVDctEsISQghR/UhAhBBCpEICIoQQIhUSECGEEKmQgAghhEiFBEQIIUQqJCBCCCFSIQERQgiRCgmIEEKIVEhAhBBCpEICIoQQIhUSECGEEKmQgAghhEiFBEQIIUQqJCBCCCFSUTUCMnjwYLd69Wr3yiuv+FfixvG3f/u37o033nCPP/64/3333Xe7rVu3ukcffdT/5jzOJx/yqwQoG2WkrM1FXV2dW758ufvP//xPN2bMmEyqEEIUR6vyQA4cOOC++OIL9+mnn2ZSRBxjx451ffr08a8Unj9/fiZVCCGKo1UJyK233upOPvlk92d/9meZlObhuuuuc//xH//h/vEf/zGTUrkMHz7c/cEf/IEv7z333JNJFUKI4tEaSBno3r2769Kli2vfvn0mpXJ59tln3e/+7u+6b33rW27v3r2ZVCGEKJ6yCsjUqVP9GgMb35ua73//+37N41//9V/d7/3e7x2y5lGIjh07ukceecRt2bLFLV261J144onu3HPPdUuWLHGvvvqqz4v8CfUMGjQoc1ZjMMijR4/234cMGdLo+qT/8z//s8+DdPJcvHhxzryANQnWJmhDPBuYMGGCW7NmjXvzzTd9Xs8//7z7wz/8Q78vXNeZNm2a27hxo78Wn3Y+dOvWzd17770+nXzY1q1b52677Ta/39aYfvrTn7r6+nqfds4557j169f7tD/5kz/xaXzye9myZf53FFvTeeCBB9yPf/xjf53Nmzf735deeqnvK0ubO3eu7wMott2BslMHq88LL7zghg0b5vdR3x/84Ae+rNb2//RP/+T7GOxeYb2MdMpDHpSZewkoG/eYtRllYu3o61//ut/fr18/N2/evOw12L9q1Sr37W9/2+9nTY7zwjDh3/3d3/ljFy1alElx/vvPf/5zd/XVV2fbj7JTf/Jk4xgrOzC+wrr/5Cc/cd/97nczextzww03+PpRN2vv22+/3ee7cuVKvyYGlI2x8Fd/9Ve+brRLWLfwvgOOoVzsowzUfc6cOf74cAwyDjjXjuNetjYS1U3ZBIQb+sorr/Q3KBvfm1JEbr75Zjdq1Cj3wQcf+Ov827/9W2ZPchgoGKjXX3/d3XLLLf4G/+3f/m3vUbz00kveSL733nvu9NNP94Mwjueee84bGGBwIEQYMoSAQcpaA8br6aefdv/zP//jfud3fsdNnjy5kTEwMFzXXHON69Chgx+8GBHqiRAcfvjh3nhh5Hv27OkmTZrU6EEAPKDzzjvPbdiwwQ/go446ypeBPOmP6dOnu4suusivEf3Lv/yLD2FxDILANRjU27dvd0cccYRvAxg4cKD7yle+4tNOOOEEn0aIkN/UKR9c95e//KVvmy996UteIDBwDQ0N7sUXX/THfPOb3/T1hWLbHVHFi8Lroz5s1I3yWn25P9555x3fJ2+//bY766yzDjGyffv2dV/72tfcv//7v/vyUs8///M/9/u4J2izTz75xLc9/VpTU+Pzp//uvPNOXwfOo39pE+owceJE3/Y/+9nP/LnHHXecFx0MNXWC3/zN3/RpAwYMcD169HD/+7//6/7rv/7L7wPEm2txTdoMY33ttddm9jrXv39/9+GHH7qnnnrKtydl+uM//mM/7qKQ769+9St37LHH+vLCGWec4Q477DB39NFHu1NPPdWnUaePP/7YT0h69erlf2/atMm3H/cUaZSBenC9KVOm+HzIG4Fg7dEE3LBxwP3J5IHx0qlTJ5+PTVRE9VI2AYl7MirX01Klwo3NQGFgzZo1K5V4sBZgAsRaAOIBzEh///d/333nO99x119/vfvhD3/oBxWGwWaeIRgqO3fnzp3upptucn//93/vLrzwQte5c2e3YsUK//0v//Iv/aDBSGOkzj//fH+OgUBgsLp27eqNFTNfBuqIESP8wPzrv/5rn8ef/umf+gGOAQoH6759+9zMmTN9ub/3ve/5sjBQMfj0AwYIAWMwYyAvv/xyP3vEAGPcMQjMYnkQAdGD3/qt33J79uzx1z/ttNN8GvnxmzLkgxkvZb3sssu8EeI6GLy/+Iu/8Ol4NtTZrlVsu2OUEdr//u//9hMB6vRHf/RHXkisvhh0rk+f0McfffSRrxPG2dixY4cbP368u+qqq7w3un///uw1MZgYWcqPtzNu3DgvWhhkrkHZuT4PJdA39DOzcISZdSaMP/fXb/zGb/h2w+jzHXHkk8kExpvjETpE3LCyc03uBzBPAbiXRo4c6dvK7gmEPW5ignGnnPQx12PigWhRd9IoB22CkX///ff9JIR2vOSSS7wAWPtx/1Bu8sCb5D62e572o03wnkNoE/pp9uzZ3sNiw+tBuM4+++zMUaJaqbo1EGZl3NTclLjJaZ4iYsAy+4kTIIzHXXfd5dNw3zHGX/7yl72xY7AlgVklBo7ZJwbFYDbOQMaY1tbWZlIPwoz9pJNOcmvXrnV33HGHT2O2iqAw2O6//34/C2Sz2SP1MJgFYrQBQ7R7925/DGVnwB955JHe0yLkZiAYlBGhw2Ay+DmPsiNOxx9/vBfHX/ziF16wEF0MD0YRTyEfnGdrLPZUHGGat956y39/9913/Sflg2LbnXbdtWuX9yCY1WL8aT+uafVF9DCstBnhMmbgGNmw3RB0mwBs27bNC7Fdk2sgoHh2zPIJw1FOrkHeHIextfOBsiNC9Bt1ZZ95deZ9EHrCK8MAIyzc04hUCN6stR+G/rPPPvP3vIHBf+KJJ/z1aVfuCfIMjwnBG+J+4Hr0NZML7jXGAEJJfbgPrI/4judL2IuyIQC0H/cu16Ds1Iu2tfFDeSm3YeOA4/GY7f61yRNiJKqbsgkIbm6UuLRSYSBhLBm8xLnTgJHAcHJjYxAMZnh/8zd/42d2XIOwBN4EM+GmhhAGs38GKUYaGPAYBQvTMdMLt8cee8wfVy4I49iMmXAPwoWoIHqWhvHFKJoQFEOudkzT7gghXuiCBQt8X7L+RAyfyQXt1q5dO29co22GBxbO9PPxD//wD35mzbXoB8rHhMPWSJKAJ/H55597bwUjzSwez8S8Ogw6IhWduecDw05dEHhCkazDUNd8IKS0J22NmCEclIP7Dq/llFNO8SFAhAZYv2GSRTsi0Ign94bB2KFNuGdDaHuDMQpclwlQtC9oS1HdlE1AiOvjETALYeM7aeWGm5zZJjcz8WlCPcXC4MU4MIhYzGMNAHDlGZTkzYI0jwUz+Jl1FQPhGWbHzNAwbAYDlfULrotRDsEAMCPEoLD2wbHM5gi7ENdnRosgh1sYM88H8X+u2bt370bGjxkxZSS0RF70G14MaYQ5qDuGDSOIseB4PvldTtK0O+2Dt8Sx1AnxQ9yI8SNu9DFtTfuFbcaaATP6JGBUMbyE3fC+qLeFDvFWuBeZzYdhI75TbvOwbP2BGTtrLYgv4SHqykTBPDrKnxRm9hhw8iF09+CDDzbyquLg/qKfCVPR3oTRaA/uDSYK1NXWYeh76oEwY+Qx9niheHUGoSs8LepEuBA4Jww3ItQ2DhCusB/Ykgq5qFzKGsJCMDAybE0hHgYDjhsbg8c6hglAMWAY7UkRZrLMXDGyFn4gxswsmHSMZj4wEBg8wikPPfSQn20Rt8aI4a6zKMzsmH0YNYz0ww8/nDn7IMzk8DLYh4jQfvbECtcnFs46wYwZM/yTXDyxlBTqSfgK48f5GBzyYh2EOjPjpy3h5Zdf9uWmDGbYTFyoH0YGoSsnadqd9qAdaFdEh7LRB6wlYFgREcKEVl+OYy2AtaSksO6BoaM/WWdB5Cgr1yB8xCeeBf1K/vQz60l4GewHW3/AcBMWQoRMqPGgKSP3orV/EswzQywp28KFC/19lQ/aAzFEaPC6bRJAyIpyEcYivMT9Rlnw9Akhsr5D3W688UYvBAZhK4T4q1/9qh+LtDHtEA3NUn/61sYB/UHYmacTw4dARHVSVgFpTrgJca1xk00AioWbHoPJAOJpIAYmj04y8+Lm5u8liAFjUPPBACZOzAAjzMMMFCN43333+ZkeMXkGEDM9DDLx4DiDweyUejGz5ukwjBaiQpiGMlAeHqNkpke+SeFaXJNBz8yV2fSZZ57pBYIyUlYDY4YBxHhj5DgXI2DXY82g3DPHZ555puh2Z7EXA8cEgo3ykgePKmMsedoKT5Bj7I8nWdcwzyAJzLLxEFgIZoGf+wMxZoGf9SwEhvYivEf/0s88Bks4Dk/HsLAQ/WpeI2nUjzrb/qQQsqJvECXqTrks33xwHQSQ69o1KT/lQnwREyAv7kMmC4S7WG9h3QZvwqD+3Dt4YogG7cP+qCeFN836CfcUITsW2vGA8AyTeoKicmn3/65l4yCmEKKqYK2CMBML/Wm88XLC4+c8XcWkh/BiCKFGPGvCYTyGXYzXJSqTqvVAhBAH4dFiFuLTrAeWEzw9HpPGy4mu8cEVV1zhvUDWHyUerQMJiBBVDgvhLGYz+29OCBnyhBprJIS8EDCeImQthb9/ikJokTUYHtfW+kfrQCEsIUQqWDTniTCezuIhELwK1hT5g1b77wyidSMBEUIIkQqFsIQQQqRCAiKEECIVEhAhhBCpkIAIIYRIhQRECCFEKiQgQgghUiEBEUIIkQoJiBBCiFRIQIQQQqRCAiKEECIVEhAhhBCpkICUGf7L6OrVq/1/KW2r3H333f7td7w8KC3WjvbWyHJD/5C//iusEOmRgAiRAMQQweET8WkqYROimmhVAsLgZubLDNhoyplsXN687nXIkCH+5TqicqF/6Kekr+cdOHCgf/Ur8Apk3scuRFtHHogQCejXr59/x4UJydKlSzN7hGi7lFVApk6d6j0ANr6XG/MweOMZWxhnx+uYMWOGf2Xm6NGj/f6nnnrKv/SmW7dufrZJWugt8N3yYgs9F4vj87l58+ZDjrnhhhti887l8USvFV0j4beFRuyYsH7FQNk4d+7cub7s0XYKyxGuA1jZw/22hW1DOS3drpOvrPn6zaDMYTvzju8o0TaMtnGUaJ5hXa29Q8J6cR7nG3gsvOObTd6lEAcpm4AgGFdeeaU34Gx8L7eIjBw50s2bN8/17t3bb9u3b3eTJk3yRoGBjdHhrWi80J/9F1xwgRs7dqzbsWOHNx6kUS7A+PB7zJgx/pO3qGHUQkNJPYYOHerz4BjyGDVqlD/uvvvuy5l3FAxT3759ffnsmoRBQoMGJ554ov+0Y5jpTpgwwacVS01NjTvttNN8GU8//XQ/Y6bOlJ26cg02rjFnzhyfbuE320cZrH60L1AXym7tRn/QRvnI12+AoaaelNGO4RqIs0H5OnTokN1PHXgbXthfIRw/bty4bJ6Ul+vmwsTE8uc8yhSKiBCiMWUTEAZslLi0Uhg/frw33AYhhaihSQLlOvXUU93ChQuzMXDy3bZtmw9VGPv37290jMW9CWMkBQPUo0cPb0At7EF+5EvZBw0a5NMAYz1r1iz/nWNWrVrlz03bjpxvZScPRIwyhG04e/Zs/xlXpylTpvhPK5PVJdpuVq9cFOq3ESNG+LY3kQKuTXsYXKO+vj7zy7m1a9e6Dz/80PXs2TOT0phevXr5z507d/pPynvZZZdlyx1Cvbp06ZJtC+B93+Tfv3//TIoQIkrVrYGEYQxCVWnAuHTq1MlNnDgxmxebeQDGvn37vGErhdraWj/Lx+CF8Jt09hv8jjNwaaDsZjyBOpO2bt26TMpBMMzMzKOGmJk954RikasuScjVb3ghiEmSd2gjghYKmz9/ft6JA4JFvejjaKgqCvU65phjfAjUylgofyFEGQUkbhZaaGZaDGY8LBzBJ6GqtOzZsycbUgo3xbcPtjWhOvov9BzSUK5+Q4Aw8MuXL8/mFXoocdCXHIdAIQr5hIS8rHzhlissKYQoo4BMnjzZD3LWINj4Tlq5sBDL9OnTS56l41WwRlBMKCoteAHRUBXwm/TQS2hKctUZA09Y6t13382kOB/7Z/YehpSMY4899pC65AojQdJ+C0OHwOyf9gG8FIx5uBaTFK7Jug6ilSscmKuPhBD5KWsIC8FgwZatnOIBZmgttm2z5BBmkYRYQoOGASGta9eumZRfh21sQdzgaaJiFk3j8o5ioRQWdO1aGETi+aSXMsOnrBs2bPD5MrvOtaAM1HnTpk3+2LCOiAV1IOYPCD+GNlwPMGxdgLKHC+AsZueiUL/RhqzVED4My0+5eIgB4tr5mmuuyRtiolz0ZxIsnBjWCwjfhfeHEKIxVbMGgqHFANq6BU94RWPxZozssVozSCtWrPAGjDQMJBDewICHce/jjz++aIMel3eU6LWIr/NZariM2P2uXbv8d2bQ0fWNKIRj1q9f32jtB2gv2s7EAMMdtgsbbckx9nit1QGjSxvkIkm/4VXgIdjj12yvvfZaoxAVgoaw2f4jjjiiYAiLp8PseESLSU1cWDWuXmwNDQ1lDcMK0dpoV1dXdyDzXVQZeB22+EwIqKXWbxCXfAY6hBn+tGnTvDdTivfVlCxbtsytXLmyYssnRKUgARElY4vTSQTMvLRKXZxGDFtSjIWoJqruMV7RcuA9IBbhugCCQAgvXxgrhMV6Qma5wn0tDWs21CffE1tCiIPIAxFFgWEN/16GP7ZkfULhHiHaHhIQIYQQqVAISwghRCokIEIIIVIhARFCCJEKCYgQQohUSECEEEKkQgIihBAiFRIQIYQQqZCACCGESIUERAghRCokIEIIIVIhARFCCJEKCUge+O+zvEbV/nMsL1zavHlzozfnVRv8M0T9p9mmgfuC+yN842M+OI73xSc9Ph/8h2TySvpfjosta6lwPcqnNzy2LiQgQrQCLr30Uv/Wy6Z+z0o5RU9UPxKQIuBflp988sn+FazlhFkjnk74Pm5RfXBfcH8097+2x5j37NnTTZkyJZNSmJYqq2hdSECEqHK2bdvmbrvtNv9u96YGwTn99NMlPMJTVgGZOnWqd2/Z+N4UMFvfunWr34jhzp07t5FLbS426eznO3FXixHbuZYewrmcY8fcdNNNmT0HsbztWhDNN/QkwjUU1h2ix9h+3tDXrVs3N3/+fP973rx5seXL56lY2b73ve/5Y+xaudY7rr/+evf4448XvI6tmYTtHj0n2gZxeYYkLatdm439vKs8PD7cwnUpO54tjPNzTHiObXFtan1DvQ2rZ5hG3hs2bPD74uL87A/vqWgdo6Q5nuty78TVJVpn219MWa0twnxsIx8jV7vHYdeKa3tRPZRNQBAM4q8dO3b0G9/LLSIM3L59+3rD3rt3b++GDxo0yNXU1GSOOAi/TzvtNDd27Fg/W1q6dKkbOXKkN8ycx0a8eNKkSdmblxt6woQJ/lg7pnPnzt6w54LBRx2XL1+ePWf37t1uxowZjQYFArFx40a/n7KT7zXXXONnjOxjEO3YscONGTPG/37qqaf8eQMHDvSfQH6cz+DMNdOk3rT7woULs9fq0aPHIUaINwp++9vfdm+++ab/Xeg69gZC0ikjdaStjEJtG0cxZbW2u/DCC3372HUoC+1G+1lY0c63Y+hPykr/coylsy1YsMDt3bvXTZ8+/ZA25TdtwHFWD9qJeztM69+/v2toaPDliMI1x40b59/YyDmUl76P1tEo9njuP463e5bjaXuD8cIxM2fOjN0fku/adp+SbvuKafcoVu7169f7fHPdz6LyKZuAhDMZIy4tLeSFeGCsuTmBTwzXvn37/O+QVatWNboxx48f38jtxiiFAjFixAgfCrABAcSU4wyDYQuX4Tm8G5x8ETbjjTfeyB5DmTdt2uQHWS4Da8f069cvk+J8fh06dHCLFy/OpMTDuVZPvtNeGGbaj43vlAdh/e53v5voOrTBrFmz/HfalLa1PKFQ2+YiX1kNrv3kk09mfjXGYv5WNoxVly5dvBE0OPfDDz/0hj6EY7lOeD9FwbOgLawetNPbb7/dKK1r1645RZ17iva1Osa1XUixx/PuduA97sDxl112mf/keMZL2Mbh/ijFXLuUdv/a177mJ12Mm6Ze8BdNT9WsgTBYEIp169ZlUnLDcTaoQsIwzOjRozOpB2fdGDwMXzFgPJghW55sEydOPMQj+uCDDzLfkoPxYlDa4GUg7tq1K6exg7h6228MBIIRJcl18DjijE5IrrbNRb6ymmGEXNcmdMJxeDC2v7a21h1zzDHeA7SyENqJChn9XV9ff8iEIQr76Us8D85BOJ5//nnvcZBGm9F2tGEUu6eYYVtZ8rVNsccDxh5DzD0X9VKKGS/FXLuUdqct8Xwp8/DhwzOpopopm4DEGbZ8xq45YaAT7zX3m0/CF+UAN97cdtvK8XTL2rVrs4aKAc5TNng3aXnttde8OERDGKVepynbNhdcc9SoUY1m1wYei5Uj3MLZLuFDKPTUEvnTXnge5lE+99xz3kCSRpvRdrRhLmiLaFksrBpHscdjiC3cRLlyhbuSUOjapba7QVm510T1UzYBmTx5sp+FElNm4ztp5aRTp05+0IYw+4nO+KPYOXGx7pAwlAPMoLjZc4FnwSBpisFAOQkhhMYrn6HKBaLBLD7XuaVeJ2nbJqFQWQ1i6xj2qPeAB0N/WT3iINxCaCecQefDwnFnnXWWe/fdd/05Ftrq06ePN9px+ZBGXaL3VC6KPT6Ec/EeEAALOYXeUyGSXruUdgc8IhOe6DqhqE7KGsJCMJixsJVbPLjxGBTMgBggYDOiQkRDI9HzGEAYUcJR4VMlDBgWTXOBITn22GOzM1ogb4xTMWCYGIBRl5/wA+nDhg3LGq98YDBYnLT2wVgOGDAgp5Ezir1OSKG2zUXasjIxwUiG8XYD4cEQEp4KjRP9wXXYuGYY6y+EtQ33tIWquA/p9zPOOMO3Vy4Qn+g9RT15QjCOYo/Ptw8vgXpSZ44D2mTRokWxhrvQtUtp95CPPvoo+3SjRKT6qZo1EMBdZwZksVZ7AoqZTT4wFgwmYsV2XnSWy6yKGRxxX45hI+yTbxGdfBlQZvjYGICEtYqBBUcGIPXiXBtUGAHS6+rqCi6eA+1AvSgDZaG+POlSaLGy2OuEJGnbONKUFYNGWyPqYbydjXwQHjNO9lgrG2Em6mgTgmisP2zzKJzHPceCsNXL0vC0860xxN1TCNgzzzyTOaIxxR4PQ4cOzR6LcDNxo3xAW9Km1je0yaeffhor0PmuXWq7R+F4PFaE+aGHHsoKnKg+2v2/0TiQ+V6VcPNxo/M0VtJZZTVhMe1Ci46ltkPS6xQCQzxt2jQvirnK0dr7TIi2QlV5IHEkjZtXI7j/hA2KfTqsWMp5HcJ5hHUkDEK0fqpKQPhL5NDdxX0mHMH6Rb64ebXC35kgjrn+DqJclPM6iAd9QsxcCNG6qSoB+dWvfpWN57IRryVuG30qpNpBJPk3DzwtVI6nm3LRFNehL3I9vimEaF1U/RqIEEKIlqHq10CEEEK0DBIQIYQQqZCACCGESIUERAghRCokIEIIIVIhARFCCJEKCYgQQohUSECEEEKkQgIihBAiFRIQIYQQqZCACCGESIUEJA+824KXDRXzn2V5r0Yp76WuFvhPyPwjxvC/I1cz9Fm+F0vFUWpfc18Ve82mppz3r/2zTu4V0TqRgLRCGLCvvPLKIa8TFfFg6Lp06VLUfyTG6PNGvbTvUKGP+K/FvMmvUl5FUGqdovDq30JvCxXVjQREpIJ/237yySdX/YujMJoXXXSR9wbiXr+ai0GDBnlja++Ej4J4I+Jxs28E69xzz23Sf9WfhkJ1Khbak3fJt7bXLYhfIwFphTBgGbjFGMS2zA9+8IOihbC2ttZ/MsuOo1evXn72HffOdM659tprK65/CtVJiChlFZCpU6f6WRcb38uNxWfZ7KVSzByZRRJLDtOikGb72eLivBaztWMIL0SxmaUdU2wM28JLc+fOPSSPsIxx+XKu7Y8eEy2XbeE6RbFlZx/HxOUVFyaLtnHc7NvgvA0bNmTzM6x/Q+L6Ll99f/SjH/l90byjZeZzzpw5bsaMGdlzo+fkomfPnv4tjjt27PC/rW9eeOEF32a8+OyYY47xeYftTF1Imz9/vj8+bCNrEytnWB4++W31JJ9c5MsnbMtofaN1guh12aL9w++4PKN9Ge2zaD5R8t1PScoVYv1jW9h+0bzCfXyn/3iHv5U92m758s5VB2uLaJ1IC/PmfNI4PklZILxm3P5yUjYBQTB4C13Hjh39xvemEJETTzzRx2iJH/M2Ql6fymDktbaWNmDAgEaNxo3FW/cQBI4ZM2aMd9XDgc3xEyZM8LNCjmHjmG7duvn9QCdSp+XLl2ePYcBhEPIZ4ii0z/HHH+/Pp0xchzp07dq1URrvFze4Kbj+zJkzG10bA0i6hQtsH3ns3bvXpzO7TlP2KVOm+GPseNo4F5SPY2hbPikn1wwHSBqifccnb6bMV9/777/fl5v35Yf069fPbd++3R9Df1O2TZs2ZfPIV78o9BUDlBAUZRw1apQvw9lnn+3vyTfeeMNv5MtvOy6sC/cqbWT3Kl5LTU2NGzp0qJs8eXI2REg5ESTKzXm0LfnkMgy58olef/369a6+vj7b/2GdgD5lTMyePdsfT98iLh988IHfz3mMIWA/m7Uh+7iHbT0l2t6Ugffw57o/SA/L+vzzz2dDa4XKFYVr0z82dmh3Xr0MhdqWNoHvfOc7vi251ocffuhGjBjh0/Plna+/KS/3qEF70RfYBvMEOZbzGbOUr1BZoFAfl5uyCQiVjRKXVioMSoup8g5vOiKaRqOa8aCzuFHnzZvnOwEYIAsXLvQ3OHFfoBNw3cN4LQY0nI3x7nAMUHjMihUrGuWTBAwdNz9QJgZVXBo3AB1vNxLpYajFjh84cKD/NDhn0qRJjcpabNnNAISDcvz48bGhHsp36qmn+jY148NxtCdGOy1xfccnAyIkWl/KYBMKGziUkYVy6gzW3+Grd3PVLwp5US7uMwwo7XTVVVdly2htFy5GY6g4h4Fvx0XvVT4x/LSjHcO1MFBcx/rOQkxmaKLE5cP1EZawLTF0lJNJktXJjB9tzz3HPWZtYmskeDdgExzGiWFtGK6n0B70WdjeZkDxeuKIekOWb5JyRbF2snajHdkKta31IxvrVbQb91Zo+HPlnaS/Q1iHg7ffftt/AuOaa3FekrIU6uOmoFWsgeSaeQAdTCOvXbs2k3IQfpMe3iiFnj5hBoAHZO4hG7MXBmupUJZQrEJyxdO5STCa0UHIwKY+JjBQbNnNCDN7Nhc6F5SvU6dOPr8wf65XCrn6LkpcfWmrDh06ZMWRwdjQ0ODzStrfubAZ/gUXXODLZx6GERpPI/R+ckEfYYhCEbPJweLFi/0n/YAnyXUxLHHE5cP1wzSMzejRo/1EhTJRJ7AyI7CUN8yD/gDyoQ0RaPo5rLsRHmvtYeLNuXi+pFm9oiAGxx577CEecqFyxWHjhnYL7+NCbYvRpYzmAYDdO2ZzcuVdqL/N+DN2yXPo/3uLjDfu0WgaxyYpS6E+bgrKJiBxBWyqQrckzFYYOOFWSU8j2QwtnIUYxZadmRTHcAMykPMJyZ49e7Juc7gNHz48c0TTkKu+fN+1a1d2tsfgssFYKhgsBP2nP/2pn2VG2yRq0KID3TCjwCwx1zEYE8IatD/Gmk/6IypaRlw+lhZOICgzYRfzCKLiEFcW2hCjx0QnLHscoQdB3tTBJhiEa9mX70EP7smxY8f67w899JDv5yTlioNrcC0MOu2HYYVCbWsCE07cqDcTE/N24vLOVc5cbWbeB6Jl54RpUKgsSfq4KSibgOCqEZskFMPGd9JaGmZUNKzNRI1cs8QQ63CDzsUo0lnNCYOaGa/dRAY3SBh2oFyEChgEUVEopezcgIgDRMsAucpXCM4xwwU2CIxcfWfkqy8w48VIsOhIPjb4bPYX7e+kkCcGY9q0aT4fwoMhofHMh51HuaKGKYR8bG2JLZ9ByJdPOIGIThxoi3wzZgw4XgqGKYkI4wWFx2ITwglGkokF52LMub/COH9IMeXimrQBM3sbB/naNq4fuce5b21yYIR5n3baaZnUxoT9DYzJI444opGnAVw3Li1JWfL1cVNQ1hAWgoEas1WCeAANyMDAiNhM0QwP6eynk+gs1NtmJ8BCHTMUw9zqcHGbPIk1NyUMaowk12LAGJSPm8pmKRaLnjVrlv8MKbbstNGiRYuyAy0flI+2JJ5sbQw8aRaWN8TOCQczZcMAGnF9F5Y5X33BQl8jR4707RQaR8QFw8NEx7Dycg8wEOPqThqDk8HPfUNZ8IDCemI8uZ4Nfj4xcBxn9eAaGEcLSeQyTNZvNiOFZcuW5WzXuHzirs8nC65xdeR4yk892c+xtu5kk5W4/qMtOJbfCLYdawYzFFraPRxrIaTbPsvL2rtQuaLQTvSrEfZNobaNiiCEhjxX3j/84Q8L9rdxxhln+HNsDYZ68IANhCHKQmUhvZg+LhetYg2kEMwOuNnNVbVHKMNZEB24YMECHzNkH9trr73WSPExaMTZecrLjuHGwNg0NcyMeKIiXGcAc7cpBwKIAbb6sdljfGnKjndjedF23Px2o0eJtjEbA4Hr5oLyYBzsGsADESHRfPl88803C9YXaBcGJBMai78bce3BzBHRYTbO73CwGlwvNI7kg7iHIsfaioUSKCfQf2E9OJbwgrVn3AwTyB+DE96XPIWWq11z5RO9PuWiTayOGGjKbMIZ9g3xfcZG9K/KTcCt/Y866ihf1qh3TxohxrCtMYi57iXqYPUlb+pjnkGScoXg4Z5zzjnZ63KulTtf29I/oXdvhAKUL+9C/Q3kvX///kPuTQi9jyRlgUJ93BS0q6urO5D5LkRZYHbJzZ7LQDQnlIUZK+GTJAMJ40loitlfLiMt8oPhwhsNn0BqKvB6HnvssSa/joinTXggovlg9s8MMnS/WwrEAPFgNpZ0FoaHYU9riXQUWk8pF0wO8EYlHi2HBESUFWLvxJVxo5sy9poEYtuEFXI9KhoHxoiwWVO6/a0ZvA/WluLCMk0B4adwHUs0LwphiVYHMWPi4ywmEzNXKKrpYbGWNRRi+mrztoMERAghRCoUwhJCCJEKCYgQQohUSECEEEKkQgIihBAiFRIQIYQQqZCACCGESIUERAghRCokIEIIIVIhARFCCJEKCYgQQohUSECEEEKkQgIihBAiFRIQIYQQqZCACCGESIFz/wc7e9GVYbUiRwAAAABJRU5ErkJggg==)\n",
        "\n",
        "Dlatego scaled dot-product attention to: czysto numeryczny zabieg stabilizacyjny analogiczny do:\n",
        "inicjalizacji wag,\n",
        "normalizacji,\n",
        "layernorm"
      ],
      "metadata": {
        "id": "rLFzKPyj8P-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = torch.randn(B,T,head_size)\n",
        "q = torch.randn(B,T,head_size)\n",
        "wei = q @ k.transpose(-2, -1) * head_size**-0.5"
      ],
      "metadata": {
        "id": "4SNbLq5z3oBw"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl6I9n9IRTSo",
        "outputId": "a9c3744b-2400-4077-fb2a-577f1beb6a6e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0449)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1tQx7oeRvtc",
        "outputId": "0116473e-5f37-48d1-d120-86acdcf8e37c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0700)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLb_odHU3iKM",
        "outputId": "ceacd702-09ab-4625-968b-1b93bc8e08e7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0918)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB82yzt44REI",
        "outputId": "0c54fc8c-6e75-446a-dacf-652b29c6b9f2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # gets too peaky, converges to one-hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpt8569BB9_f",
        "outputId": "5d8b910a-6192-44ba-ebb2-497d88e0b629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm1d: # (used to be BatchNorm1d)\n",
        "\n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "    self.eps = eps\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    # calculate the forward pass\n",
        "    xmean = x.mean(1, keepdim=True) # batch mean\n",
        "    xvar = x.var(1, keepdim=True) # batch variance\n",
        "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "    self.out = self.gamma * xhat + self.beta\n",
        "    return self.out\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "module = LayerNorm1d(100)\n",
        "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
        "x = module(x)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Num7sX9CKOH",
        "outputId": "929ceb78-a639-41d6-aac7-12997b5c93f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "633T2cmnW1uk",
        "outputId": "7720fa58-0478-4e8a-86a7-502d4cce9443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1469), tensor(0.8803))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN9cK9BoXCYb",
        "outputId": "6368ece0-600e-417d-8a91-7c1e5d750ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-9.5367e-09), tensor(1.0000))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# French to English translation example:\n",
        "\n",
        "# <--------- ENCODE ------------------><--------------- DECODE ----------------->\n",
        "# les réseaux de neurones sont géniaux! <START> neural networks are awesome!<END>\n",
        "\n"
      ],
      "metadata": {
        "id": "dRJH6wM_XFfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full finished code, for reference\n",
        "\n",
        "You may want to refer directly to the git repo instead though."
      ],
      "metadata": {
        "id": "ZcvKeBXoZFOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.0\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "# super simple bigram model\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "hoelkOrFY8bN",
        "outputId": "6745cc0c-07b5-4c64-be9c-253668326ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'input.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4113926622.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fjjvMifYZf7x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}